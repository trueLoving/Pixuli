#![deny(clippy::all)]

use napi_derive::napi;
use image::{DynamicImage, GenericImageView};
use webp::{Encoder, PixelLayout};
use napi::Error as NapiError;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::Path;
use std::fs;

#[napi]
pub fn plus_100(input: u32) -> u32 {
  input + 100
}

/// WebP压缩配置
#[napi(object)]
#[derive(Clone)]
pub struct WebPCompressOptions {
  /// 压缩质量 (0-100)
  pub quality: Option<u8>,
  /// 是否使用无损压缩
  pub lossless: Option<bool>,
}

/// WebP压缩结果
#[napi(object)]
pub struct WebPCompressResult {
  /// 压缩后的数据
  pub data: Vec<u8>,
  /// 原始大小
  pub original_size: u32,
  /// 压缩后大小
  pub compressed_size: u32,
  /// 压缩率 (0-1)
  pub compression_ratio: f64,
  /// 压缩后的宽度
  pub width: u32,
  /// 压缩后的高度
  pub height: u32,
}

/// 压缩图片为WebP格式
#[napi]
pub fn compress_to_webp(
  image_data: Vec<u8>,
  options: Option<WebPCompressOptions>,
) -> Result<WebPCompressResult, NapiError> {
  // 解析图片
  let img = image::load_from_memory(&image_data)
    .map_err(|e| NapiError::new(napi::Status::InvalidArg, format!("Failed to load image: {}", e)))?;

  let (width, height) = img.dimensions();
  let original_size = image_data.len() as u32;

  // 转换为RGBA格式
  let rgba_img = img.to_rgba8();
  
  // 创建WebP编码器
  let encoder = Encoder::new(
    &rgba_img,
    PixelLayout::Rgba,
    width,
    height,
  );

  // 配置质量
  let quality = options
    .as_ref()
    .and_then(|opts| opts.quality)
    .unwrap_or(80) as f32;

  // 编码为WebP
  let webp_memory = encoder.encode(quality);
  let webp_data = webp_memory.to_vec();

  let compressed_size = webp_data.len() as u32;
  let compression_ratio = if original_size > 0 {
    1.0 - (compressed_size as f64 / original_size as f64)
  } else {
    0.0
  };

  Ok(WebPCompressResult {
    data: webp_data,
    original_size,
    compressed_size,
    compression_ratio,
    width,
    height,
  })
}

/// 批量压缩图片为WebP格式
#[napi]
pub fn batch_compress_to_webp(
  images_data: Vec<Vec<u8>>,
  options: Option<WebPCompressOptions>,
) -> Result<Vec<WebPCompressResult>, NapiError> {
  let mut results = Vec::new();
  
  for image_data in images_data {
    match compress_to_webp(image_data, options.clone()) {
      Ok(result) => results.push(result),
      Err(e) => return Err(NapiError::new(napi::Status::GenericFailure, format!("Batch compression failed: {}", e))),
    }
  }
  
  Ok(results)
}

/// 获取图片信息
#[napi]
pub fn get_image_info(image_data: Vec<u8>) -> Result<String, NapiError> {
  let img = image::load_from_memory(&image_data)
    .map_err(|e| NapiError::new(napi::Status::InvalidArg, format!("Failed to load image: {}", e)))?;

  let (width, height) = img.dimensions();
  let format = match img {
    DynamicImage::ImageRgb8(_) => "RGB8",
    DynamicImage::ImageRgba8(_) => "RGBA8",
    DynamicImage::ImageLuma8(_) => "Luma8",
    DynamicImage::ImageLumaA8(_) => "LumaA8",
    _ => "Unknown",
  };

  let info = serde_json::json!({
    "width": width,
    "height": height,
    "format": format,
    "size": image_data.len(),
    "channels": match img {
      DynamicImage::ImageRgb8(_) => 3,
      DynamicImage::ImageRgba8(_) => 4,
      DynamicImage::ImageLuma8(_) => 1,
      DynamicImage::ImageLumaA8(_) => 2,
      _ => 0,
    }
  });

  Ok(info.to_string())
}

/// AI 模型类型
#[napi]
#[derive(Clone, Serialize, Deserialize)]
pub enum AIModelType {
  TensorFlow,
  TensorFlowLite,
  ONNX,
  LocalLLM,
  RemoteAPI,
}

/// AI 分析配置
#[napi(object)]
#[derive(Clone, Serialize, Deserialize)]
pub struct AIAnalysisConfig {
  /// 模型类型
  pub model_type: AIModelType,
  /// 模型路径（本地模型）
  pub model_path: Option<String>,
  /// API 端点（远程模型）
  pub api_endpoint: Option<String>,
  /// API 密钥
  pub api_key: Option<String>,
  /// 是否使用 GPU
  pub use_gpu: Option<bool>,
  /// 置信度阈值
  pub confidence_threshold: Option<f64>,
}

/// 图片分析结果
#[napi(object)]
#[derive(Clone, Serialize, Deserialize)]
pub struct ImageAnalysisResult {
  /// 图片类型/格式
  pub image_type: String,
  /// 检测到的标签
  pub tags: Vec<String>,
  /// 图片描述
  pub description: String,
  /// 置信度分数
  pub confidence: f64,
  /// 检测到的物体
  pub objects: Vec<DetectedObject>,
  /// 颜色分析
  pub colors: Vec<ColorInfo>,
  /// 场景类型
  pub scene_type: String,
  /// 分析时间（毫秒）
  pub analysis_time: f64,
  /// 使用的模型
  pub model_used: String,
}

/// 检测到的物体
#[napi(object)]
#[derive(Clone, Serialize, Deserialize)]
pub struct DetectedObject {
  /// 物体名称
  pub name: String,
  /// 置信度
  pub confidence: f64,
  /// 边界框坐标
  pub bbox: BoundingBox,
  /// 类别
  pub category: String,
}

/// 边界框
#[napi(object)]
#[derive(Clone, Serialize, Deserialize)]
pub struct BoundingBox {
  pub x: f64,
  pub y: f64,
  pub width: f64,
  pub height: f64,
}

/// 颜色信息
#[napi(object)]
#[derive(Clone, Serialize, Deserialize)]
pub struct ColorInfo {
  /// 颜色名称
  pub name: String,
  /// RGB 值
  pub rgb: (u8, u8, u8),
  /// 占比
  pub percentage: f64,
  /// 十六进制值
  pub hex: String,
}

/// 分析图片内容（使用 AI 模型）
#[napi]
pub fn analyze_image_with_ai(
  image_data: Vec<u8>,
  config: AIAnalysisConfig,
) -> Result<ImageAnalysisResult, NapiError> {
  let start_time = std::time::Instant::now();
  
  // 解析图片
  let img = image::load_from_memory(&image_data)
    .map_err(|e| NapiError::new(napi::Status::InvalidArg, format!("Failed to load image: {}", e)))?;

  let (width, height) = img.dimensions();
  
  // 获取图片格式
  let image_type = detect_image_format(&image_data);
  
  // 基础图片分析
  let mut tags = Vec::new();
  let mut description = String::new();
  let mut objects = Vec::new();
  let mut colors = Vec::new();
  let mut scene_type = String::new();
  
  // 分析图片尺寸和比例
  let aspect_ratio = width as f64 / height as f64;
  let (dimension_tags, primary_scene) = analyze_aspect_ratio(aspect_ratio, width, height);
  tags.extend(dimension_tags);
  scene_type = primary_scene;
  
  // 分析图片格式和特征
  let (format_tags, format_description) = analyze_image_format(&image_type, &img);
  tags.extend(format_tags);
  description.push_str(&format_description);
  
  // 分析主要颜色
  let dominant_colors = analyze_dominant_colors(&img);
  for (i, color) in dominant_colors.iter().enumerate() {
    colors.push(ColorInfo {
      name: get_enhanced_color_name(*color),
      rgb: *color,
      percentage: match i {
        0 => 0.45,
        1 => 0.25,
        2 => 0.15,
        _ => 0.05,
      },
      hex: format!("#{:02X}{:02X}{:02X}", color.0, color.1, color.2),
    });
  }
  
  // 增强的内容分析
  let (content_tags, content_description) = analyze_image_content(&img, &colors);
  tags.extend(content_tags);
  if !content_description.is_empty() {
    description.push_str("。");
    description.push_str(&content_description);
  }
  
  // 根据模型类型进行 AI 分析
  let model_used = match config.model_type {
    AIModelType::TensorFlow => {
      // 这里应该调用 TensorFlow.js 模型
      "TensorFlow".to_string()
    },
    AIModelType::TensorFlowLite => {
      // 这里应该调用 TensorFlow Lite 模型
      "TensorFlow Lite".to_string()
    },
    AIModelType::ONNX => {
      // 这里应该调用 ONNX 模型
      "ONNX".to_string()
    },
    AIModelType::LocalLLM => {
      // 这里应该调用本地 LLM 模型
      "LocalLLM".to_string()
    },
    AIModelType::RemoteAPI => {
      // 这里应该调用远程 API
      "RemoteAPI".to_string()
    },
  };
  
  // 智能物体检测基于图像特征
  let detected_objects = detect_objects_from_features(width, height, aspect_ratio, &colors, &scene_type);
  objects.extend(detected_objects);
  
  let analysis_time = start_time.elapsed().as_millis() as f64;
  
  Ok(ImageAnalysisResult {
    image_type,
    tags,
    description,
    confidence: 0.85,
    objects,
    colors,
    scene_type,
    analysis_time,
    model_used,
  })
}

/// 检测图片格式
fn detect_image_format(data: &[u8]) -> String {
  if data.len() < 4 {
    return "Unknown".to_string();
  }
  
  // 检查文件头
  if data.starts_with(&[0xFF, 0xD8, 0xFF]) {
    "JPEG".to_string()
  } else if data.starts_with(&[0x89, 0x50, 0x4E, 0x47]) {
    "PNG".to_string()
  } else if data.starts_with(b"GIF8") {
    "GIF".to_string()
  } else if data.starts_with(b"RIFF") && data.len() > 12 && &data[8..12] == b"WEBP" {
    "WebP".to_string()
  } else if data.starts_with(&[0x42, 0x4D]) {
    "BMP".to_string()
  } else {
    "Unknown".to_string()
  }
}

/// 分析主要颜色
fn analyze_dominant_colors(img: &DynamicImage) -> Vec<(u8, u8, u8)> {
  let mut color_counts: HashMap<(u8, u8, u8), u32> = HashMap::new();
  
  // 简化采样
  let (width, height) = img.dimensions();
  let step_x = width / 32;
  let step_y = height / 32;
  
  for y in (0..height).step_by(step_y as usize) {
    for x in (0..width).step_by(step_x as usize) {
      if x < width && y < height {
        let pixel = img.get_pixel(x, y);
        let rgb = (pixel[0], pixel[1], pixel[2]);
        *color_counts.entry(rgb).or_insert(0) += 1;
      }
    }
  }
  
  // 获取最常见的颜色
  let mut colors: Vec<_> = color_counts.into_iter().collect();
  colors.sort_by(|a, b| b.1.cmp(&a.1));
  
  colors.into_iter().take(3).map(|(color, _)| color).collect()
}

/// 获取颜色名称
fn get_color_name(rgb: (u8, u8, u8)) -> String {
  let (r, g, b) = rgb;
  
  if r > 200 && g > 200 && b > 200 {
    "白色".to_string()
  } else if r < 50 && g < 50 && b < 50 {
    "黑色".to_string()
  } else if r > g && r > b {
    "红色".to_string()
  } else if g > r && g > b {
    "绿色".to_string()
  } else if b > r && b > g {
    "蓝色".to_string()
  } else if r > 150 && g > 150 && b < 100 {
    "黄色".to_string()
  } else if r > 150 && g < 100 && b > 150 {
    "紫色".to_string()
  } else if r < 100 && g > 150 && b > 150 {
    "青色".to_string()
  } else {
    "混合色".to_string()
  }
}

/// 批量分析图片
#[napi]
pub fn batch_analyze_images_with_ai(
  images_data: Vec<Vec<u8>>,
  config: AIAnalysisConfig,
) -> Result<Vec<ImageAnalysisResult>, NapiError> {
  let mut results = Vec::new();
  
  for image_data in images_data {
    match analyze_image_with_ai(image_data, config.clone()) {
      Ok(result) => results.push(result),
      Err(e) => return Err(NapiError::new(napi::Status::GenericFailure, format!("Batch analysis failed: {}", e))),
    }
  }
  
  Ok(results)
}

/// 检查模型是否可用
#[napi]
pub fn check_model_availability(model_path: String) -> Result<bool, NapiError> {
  // 检查模型文件是否存在
  Ok(std::path::Path::new(&model_path).exists())
}

/// 获取支持的模型列表
#[napi]
pub fn get_supported_models() -> Result<Vec<String>, NapiError> {
  Ok(vec![
    "mobilenet_v2".to_string(),
    "resnet50".to_string(),
    "yolov5".to_string(),
    "clip".to_string(),
    "llama2".to_string(),
  ])
}

/// TensorFlow 模型分析器
struct TensorFlowAnalyzer {
  model_path: String,
  labels: Vec<String>,
}

impl TensorFlowAnalyzer {
  fn new(model_path: String) -> Result<Self, NapiError> {
    // 加载标签文件
    let labels_path = model_path.replace(".onnx", "_labels.txt");
    let labels = if Path::new(&labels_path).exists() {
      fs::read_to_string(&labels_path)
        .map_err(|e| NapiError::new(napi::Status::InvalidArg, format!("Failed to read labels: {}", e)))?
        .lines()
        .map(|s| s.to_string())
        .collect()
    } else {
      // 默认 ImageNet 标签
      vec![
        "background".to_string(),
        "person".to_string(),
        "bicycle".to_string(),
        "car".to_string(),
        "motorcycle".to_string(),
        "airplane".to_string(),
        "bus".to_string(),
        "train".to_string(),
        "truck".to_string(),
        "boat".to_string(),
      ]
    };

    Ok(TensorFlowAnalyzer {
      model_path,
      labels,
    })
  }

  fn analyze_image(&self, image_data: &[u8]) -> Result<ImageAnalysisResult, NapiError> {
    let start_time = std::time::Instant::now();
    
    // 加载和预处理图片
    let img = image::load_from_memory(image_data)
      .map_err(|e| NapiError::new(napi::Status::InvalidArg, format!("Failed to load image: {}", e)))?;
    
    // 调整图片大小到模型输入尺寸 (224x224 for MobileNet)
    let resized_img = img.resize_exact(224, 224, image::imageops::FilterType::Lanczos3);
    
    // 转换为 RGB 并归一化
    let rgb_img = resized_img.to_rgb8();
    let mut input_data = Vec::new();
    
    for pixel in rgb_img.pixels() {
      // 归一化到 [0, 1] 范围
      input_data.push(pixel[0] as f32 / 255.0);
      input_data.push(pixel[1] as f32 / 255.0);
      input_data.push(pixel[2] as f32 / 255.0);
    }

    // 模拟模型推理（实际实现需要加载 ONNX 模型）
    let predictions = self.simulate_inference(&input_data);
    
    // 解析结果
    let mut tags = Vec::new();
    let mut objects = Vec::new();
    let mut description = String::new();
    
    for (i, &confidence) in predictions.iter().enumerate() {
      if confidence > 0.1 && i < self.labels.len() {
        let label = &self.labels[i];
        tags.push(label.clone());
        
        if confidence > 0.5 {
          objects.push(DetectedObject {
            name: label.clone(),
            confidence,
            bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 1.0 },
            category: "object".to_string(),
          });
        }
      }
    }

    // 生成描述
    if !objects.is_empty() {
      let object_names: Vec<String> = objects.iter().map(|o| o.name.clone()).collect();
      description = format!("图片中包含: {}", object_names.join(", "));
    } else {
      description = "未检测到明显的物体".to_string();
    }

    // 分析颜色
    let color_tuples = analyze_dominant_colors(&img);
    let colors: Vec<ColorInfo> = color_tuples.into_iter().map(|(r, g, b)| {
      let hex = format!("#{:02x}{:02x}{:02x}", r, g, b);
      let color_name = get_color_name((r, g, b));
      ColorInfo {
        name: color_name,
        rgb: (r, g, b),
        percentage: 0.1, // 模拟百分比
        hex
      }
    }).collect();

    Ok(ImageAnalysisResult {
      image_type: detect_image_format(image_data),
      tags,
      description,
      confidence: predictions.iter().fold(0.0, |a, &b| a.max(b)),
      objects,
      colors,
      scene_type: "general".to_string(),
      analysis_time: start_time.elapsed().as_millis() as f64,
      model_used: "tensorflow_mobilenet".to_string(),
    })
  }

  fn simulate_inference(&self, _input_data: &[f32]) -> Vec<f64> {
    // 模拟推理结果 - 实际实现需要加载 ONNX 模型
    let mut predictions = vec![0.0; self.labels.len()];
    
    // 模拟一些随机但合理的预测结果
    for i in 0..predictions.len() {
      predictions[i] = if i < 5 { 0.8 - i as f64 * 0.1 } else { 0.1 };
    }
    
    predictions
  }
}

/// 使用 TensorFlow 模型分析图片
#[napi]
pub fn analyze_image_with_tensorflow(
  image_data: Vec<u8>,
  model_path: String,
) -> Result<ImageAnalysisResult, NapiError> {
  let analyzer = TensorFlowAnalyzer::new(model_path)?;
  analyzer.analyze_image(&image_data)
}

/// 下载 TensorFlow 模型
#[napi]
pub fn download_tensorflow_model(
  model_name: String,
  model_url: String,
) -> Result<String, NapiError> {
  // 创建模型目录
  let models_dir = Path::new("./models");
  if !models_dir.exists() {
    fs::create_dir_all(models_dir)
      .map_err(|e| NapiError::new(napi::Status::GenericFailure, format!("Failed to create models directory: {}", e)))?;
  }

  let model_path = models_dir.join(format!("{}.onnx", model_name));
  let model_path_str = model_path.to_string_lossy().to_string();

  // 模拟下载过程 - 实际实现需要 HTTP 客户端
  // 这里我们创建一个占位符文件
  let placeholder_content = format!("# TensorFlow model placeholder for {}\n# URL: {}", model_name, model_url);
  fs::write(&model_path, placeholder_content)
    .map_err(|e| NapiError::new(napi::Status::GenericFailure, format!("Failed to create model file: {}", e)))?;

  Ok(model_path_str)
}

/// TensorFlow Lite 分析器
struct TensorFlowLiteAnalyzer {
  model_path: String,
  labels: Vec<String>,
}

impl TensorFlowLiteAnalyzer {
  fn new(model_path: String) -> Result<Self, NapiError> {
    // 加载标签文件
    let labels_path = model_path.replace(".tflite", "_labels.txt");
    let labels = if Path::new(&labels_path).exists() {
      fs::read_to_string(&labels_path)
        .map_err(|e| NapiError::new(napi::Status::InvalidArg, format!("Failed to read labels: {}", e)))?
        .lines()
        .map(|s| s.to_string())
        .collect()
    } else {
      // 默认 ImageNet 标签
      vec![
        "background".to_string(),
        "person".to_string(),
        "bicycle".to_string(),
        "car".to_string(),
        "motorcycle".to_string(),
        "airplane".to_string(),
        "bus".to_string(),
        "train".to_string(),
        "truck".to_string(),
        "boat".to_string(),
      ]
    };

    Ok(TensorFlowLiteAnalyzer {
      model_path,
      labels,
    })
  }

  fn analyze_image(&self, image_data: &[u8]) -> Result<ImageAnalysisResult, NapiError> {
    let start_time = std::time::Instant::now();
    
    // 解析图片
    let img = image::load_from_memory(image_data)
      .map_err(|e| NapiError::new(napi::Status::InvalidArg, format!("Failed to load image: {}", e)))?;

    let (width, height) = img.dimensions();
    
    // 获取图片格式
    let image_type = detect_image_format(image_data);
    
    // 基础图片分析
    let mut tags = Vec::new();
    let mut description = String::new();
    let mut objects = Vec::new();
    let mut colors = Vec::new();
    let mut scene_type = String::new();
    
    // 分析图片尺寸和比例
    let aspect_ratio = width as f64 / height as f64;
    if aspect_ratio > 1.5 {
      tags.push("宽屏".to_string());
      scene_type = "风景".to_string();
    } else if aspect_ratio < 0.67 {
      tags.push("竖屏".to_string());
      scene_type = "人像".to_string();
    } else {
      tags.push("方形".to_string());
      scene_type = "通用".to_string();
    }
    
    // 分析图片格式
    match image_type.as_str() {
      "JPEG" => {
        tags.push("照片".to_string());
        description.push_str("这是一张JPEG格式的照片");
      },
      "PNG" => {
        tags.push("图片".to_string());
        if img.color().has_alpha() {
          tags.push("透明背景".to_string());
          description.push_str("这是一张PNG格式的图片，支持透明背景");
        } else {
          description.push_str("这是一张PNG格式的图片");
        }
      },
      "WebP" => {
        tags.push("现代格式".to_string());
        description.push_str("这是一张WebP格式的现代图片");
      },
      "GIF" => {
        tags.push("动图".to_string());
        description.push_str("这是一张GIF格式的动图");
      },
      _ => {
        description.push_str("这是一张图片");
      }
    }
    
    // 颜色分析
    let rgb_img = img.to_rgb8();
    let pixels: Vec<_> = rgb_img.pixels().collect();
    let total_pixels = pixels.len() as f64;
    
    // 简单的颜色分析
    let mut color_counts = std::collections::HashMap::new();
    for pixel in &pixels {
      let r = pixel[0] as u8;
      let g = pixel[1] as u8;
      let b = pixel[2] as u8;
      
      // 将颜色量化到16个级别
      let quantized_r = (r / 16) * 16;
      let quantized_g = (g / 16) * 16;
      let quantized_b = (b / 16) * 16;
      
      let color_key = (quantized_r, quantized_g, quantized_b);
      *color_counts.entry(color_key).or_insert(0) += 1;
    }
    
    // 获取主要颜色
    let mut color_vec: Vec<_> = color_counts.into_iter().collect();
    color_vec.sort_by(|a, b| b.1.cmp(&a.1));
    
    for (i, ((r, g, b), count)) in color_vec.iter().take(5).enumerate() {
      let percentage = *count as f64 / total_pixels;
      if percentage > 0.01 { // 只包含占比超过1%的颜色
        let hex = format!("#{:02x}{:02x}{:02x}", r, g, b);
        let color_name = match i {
          0 => "主色调",
          1 => "次要色",
          2 => "辅助色",
          _ => "其他色",
        };
        
        colors.push(ColorInfo {
          name: color_name.to_string(),
          rgb: (*r, *g, *b),
          percentage,
          hex,
        });
      }
    }
    
    // 模拟AI分析结果
    let confidence = 0.85; // 模拟置信度
    
    // 添加一些基于图片特征的标签
    if width > height {
      tags.push("横向".to_string());
    } else if height > width {
      tags.push("纵向".to_string());
    }
    
    if width > 2000 || height > 2000 {
      tags.push("高分辨率".to_string());
    }
    
    // 基于颜色特征添加标签
    if colors.iter().any(|c| c.rgb.0 > 200 && c.rgb.1 > 200 && c.rgb.2 > 200) {
      tags.push("明亮".to_string());
    }
    if colors.iter().any(|c| c.rgb.0 < 50 && c.rgb.1 < 50 && c.rgb.2 < 50) {
      tags.push("暗调".to_string());
    }
    
    // 模拟物体检测
    if aspect_ratio > 1.2 {
      objects.push(DetectedObject {
        name: "风景".to_string(),
        confidence: 0.8,
        bbox: BoundingBox {
          x: 0.0,
          y: 0.0,
          width: width as f64,
          height: height as f64,
        },
        category: "场景".to_string(),
      });
    }
    
    let analysis_time = start_time.elapsed().as_millis() as f64;
    
    Ok(ImageAnalysisResult {
      image_type,
      tags,
      description,
      confidence,
      objects,
      colors,
      scene_type,
      analysis_time,
      model_used: "TensorFlow Lite".to_string(),
    })
  }
}

/// 使用 TensorFlow Lite 模型分析图片
#[napi]
pub fn analyze_image_with_tensorflow_lite(
  image_data: Vec<u8>,
  model_path: String,
) -> Result<ImageAnalysisResult, NapiError> {
  let analyzer = TensorFlowLiteAnalyzer::new(model_path)?;
  analyzer.analyze_image(&image_data)
}

/// 分析图片宽高比和尺寸特征
fn analyze_aspect_ratio(aspect_ratio: f64, width: u32, height: u32) -> (Vec<String>, String) {
  let mut tags = Vec::new();
  let scene_type;
  
  // 分析宽高比
  if aspect_ratio > 2.0 {
    tags.push("超宽屏".to_string());
    tags.push("全景".to_string());
    scene_type = "风景".to_string();
  } else if aspect_ratio > 1.5 {
    tags.push("宽屏".to_string());
    tags.push("横向构图".to_string());
    scene_type = "风景".to_string();
  } else if aspect_ratio < 0.5 {
    tags.push("超高".to_string());
    tags.push("纵向构图".to_string());
    scene_type = "人像".to_string();
  } else if aspect_ratio < 0.67 {
    tags.push("竖屏".to_string());
    tags.push("肖像".to_string());
    scene_type = "人像".to_string();
  } else if aspect_ratio > 0.9 && aspect_ratio < 1.1 {
    tags.push("方形".to_string());
    tags.push("正方形构图".to_string());
    scene_type = "通用".to_string();
  } else {
    tags.push("标准比例".to_string());
    scene_type = "通用".to_string();
  }
  
  // 分析分辨率
  let total_pixels = width * height;
  if total_pixels > 20_000_000 {
    tags.push("超高分辨率".to_string());
    tags.push("专业级".to_string());
  } else if total_pixels > 8_000_000 {
    tags.push("高分辨率".to_string());
    tags.push("高清".to_string());
  } else if total_pixels > 2_000_000 {
    tags.push("标准分辨率".to_string());
  } else {
    tags.push("低分辨率".to_string());
  }
  
  // 添加尺寸标签
  if width > 4000 || height > 4000 {
    tags.push("4K级别".to_string());
  }
  if width > 1920 || height > 1080 {
    tags.push("全高清".to_string());
  }
  
  (tags, scene_type)
}

/// 分析图片格式和特征
fn analyze_image_format(image_type: &str, img: &DynamicImage) -> (Vec<String>, String) {
  let mut tags = Vec::new();
  let description;
  
  match image_type {
    "JPEG" => {
      tags.push("照片".to_string());
      tags.push("压缩格式".to_string());
      description = "这是一张JPEG格式的数字照片，通常来自相机或手机拍摄".to_string();
    },
    "PNG" => {
      tags.push("图像".to_string());
      tags.push("无损格式".to_string());
      if img.color().has_alpha() {
        tags.push("透明背景".to_string());
        tags.push("支持透明".to_string());
        description = "这是一张PNG格式的图像，支持透明背景，常用于图标、Logo或需要透明效果的设计".to_string();
      } else {
        description = "这是一张PNG格式的图像，采用无损压缩，保证了图像质量".to_string();
      }
    },
    "WebP" => {
      tags.push("现代格式".to_string());
      tags.push("高效压缩".to_string());
      tags.push("网络优化".to_string());
      description = "这是一张WebP格式的现代图像，具有更好的压缩率和质量平衡，适合网络传输".to_string();
    },
    "GIF" => {
      tags.push("动图".to_string());
      tags.push("动画".to_string());
      tags.push("循环播放".to_string());
      description = "这是一张GIF格式的动态图像，支持动画效果和循环播放".to_string();
    },
    "BMP" => {
      tags.push("位图".to_string());
      tags.push("无压缩".to_string());
      description = "这是一张BMP格式的位图图像，未经压缩，文件较大但保真度高".to_string();
    },
    "SVG" => {
      tags.push("矢量图".to_string());
      tags.push("可缩放".to_string());
      tags.push("几何图形".to_string());
      description = "这是一张SVG格式的矢量图像，可以无损缩放到任意大小".to_string();
    },
    _ => {
      tags.push("未知格式".to_string());
      description = "这是一张图像文件".to_string();
    }
  }
  
  (tags, description)
}

/// 增强的图片内容分析
fn analyze_image_content(_img: &DynamicImage, colors: &[ColorInfo]) -> (Vec<String>, String) {
  let mut tags = Vec::new();
  let mut description_parts = Vec::new();
  
  // 基于颜色分析内容
  let dominant_color = colors.first();
  if let Some(color) = dominant_color {
    match color.rgb {
      // 绿色主导 - 可能是自然场景
      (r, g, b) if g > r + 30 && g > b + 30 => {
        tags.extend(vec!["自然".to_string(), "绿色植物".to_string(), "户外".to_string()]);
        description_parts.push("图像以绿色为主，可能包含植物、草地或自然景观");
      },
      // 蓝色主导 - 可能是天空或水
      (r, g, b) if b > r + 30 && b > g + 30 => {
        tags.extend(vec!["蓝色".to_string(), "天空".to_string(), "水景".to_string()]);
        description_parts.push("图像以蓝色为主，可能包含天空、海洋或水体");
      },
      // 红色/橙色主导 - 可能是日落或暖色调
      (r, g, b) if r > g + 20 && r > b + 20 => {
        tags.extend(vec!["暖色调".to_string(), "红色系".to_string()]);
        if r > 180 && g > 100 && g < 150 {
          tags.push("日落色彩".to_string());
          description_parts.push("图像具有温暖的色调，可能是日落、夕阳或暖光环境");
        } else {
          description_parts.push("图像以红色系为主，色彩温暖醒目");
        }
      },
      // 黑白或灰度
      (r, g, b) if (r as i16 - g as i16).abs() < 20 && (g as i16 - b as i16).abs() < 20 => {
        if r < 50 {
          tags.extend(vec!["黑白".to_string(), "低调".to_string(), "深色".to_string()]);
          description_parts.push("图像整体较暗，可能是夜景或低光环境");
        } else if r > 200 {
          tags.extend(vec!["明亮".to_string(), "高调".to_string(), "浅色".to_string()]);
          description_parts.push("图像整体明亮，色调清淡");
        } else {
          tags.extend(vec!["中性色调".to_string(), "灰度".to_string()]);
          description_parts.push("图像具有中性的灰度色调");
        }
      },
      _ => {
        description_parts.push("图像具有丰富的色彩层次");
      }
    }
  }
  
  // 基于颜色多样性分析
  if colors.len() > 4 {
    tags.push("色彩丰富".to_string());
    description_parts.push("包含多种颜色，层次丰富");
  } else if colors.len() <= 2 {
    tags.push("色彩简洁".to_string());
    description_parts.push("色彩搭配简洁明了");
  }
  
  // 分析亮度分布
  let avg_brightness: f64 = colors.iter()
    .map(|c| (c.rgb.0 as f64 + c.rgb.1 as f64 + c.rgb.2 as f64) / 3.0)
    .sum::<f64>() / colors.len() as f64;
    
  if avg_brightness > 180.0 {
    tags.push("高亮度".to_string());
    description_parts.push("整体亮度较高，视觉效果明亮");
  } else if avg_brightness < 80.0 {
    tags.push("低亮度".to_string());
    description_parts.push("整体亮度较低，氛围偏暗");
  }
  
  let final_description = if description_parts.is_empty() {
    "这是一张色彩协调的图像".to_string()
  } else {
    description_parts.join("，")
  };
  
  (tags, final_description)
}

/// 增强的颜色名称识别
fn get_enhanced_color_name(rgb: (u8, u8, u8)) -> String {
  let (r, g, b) = rgb;
  
  // 计算颜色的HSV值来更准确地识别颜色
  let r_f = r as f64 / 255.0;
  let g_f = g as f64 / 255.0;
  let b_f = b as f64 / 255.0;
  
  let max = r_f.max(g_f).max(b_f);
  let min = r_f.min(g_f).min(b_f);
  let delta = max - min;
  
  // 计算饱和度
  let saturation = if max > 0.0 { delta / max } else { 0.0 };
  
  // 计算明度
  let value = max;
  
  // 低饱和度的情况（灰度色）
  if saturation < 0.2 {
    if value > 0.9 {
      return "纯白".to_string();
    } else if value > 0.7 {
      return "浅灰".to_string();
    } else if value > 0.3 {
      return "中灰".to_string();
    } else if value > 0.1 {
      return "深灰".to_string();
    } else {
      return "纯黑".to_string();
    }
  }
  
  // 高饱和度的情况（彩色）
  match (r, g, b) {
    // 红色系
    (r, g, b) if r > g + 30 && r > b + 30 => {
      if r > 200 && g < 100 && b < 100 {
        "鲜红色".to_string()
      } else if r > 150 && g > 50 && g < 120 && b < 80 {
        "橙红色".to_string()
      } else if r > 120 && g < 80 && b < 80 {
        "深红色".to_string()
      } else {
        "红色系".to_string()
      }
    },
    // 绿色系
    (r, g, b) if g > r + 30 && g > b + 30 => {
      if g > 200 && r < 100 && b < 100 {
        "鲜绿色".to_string()
      } else if r > 100 && g > 150 && b < 80 {
        "黄绿色".to_string()
      } else if r < 80 && g > 120 && b < 80 {
        "深绿色".to_string()
      } else if r < 100 && g > 150 && b > 100 {
        "青绿色".to_string()
      } else {
        "绿色系".to_string()
      }
    },
    // 蓝色系
    (r, g, b) if b > r + 30 && b > g + 30 => {
      if b > 200 && r < 100 && g < 100 {
        "鲜蓝色".to_string()
      } else if r < 80 && g > 100 && b > 150 {
        "青蓝色".to_string()
      } else if r > 100 && g < 80 && b > 150 {
        "紫蓝色".to_string()
      } else if r < 80 && g < 80 && b > 120 {
        "深蓝色".to_string()
      } else {
        "蓝色系".to_string()
      }
    },
    // 黄色系
    (r, g, b) if r > 150 && g > 150 && b < 100 => {
      if r > 200 && g > 200 && b < 50 {
        "鲜黄色".to_string()
      } else if r > 180 && g > 140 && b < 80 {
        "金黄色".to_string()
      } else {
        "黄色系".to_string()
      }
    },
    // 紫色系
    (r, g, b) if r > 100 && g < 100 && b > 100 => {
      if r > 150 && g < 80 && b > 150 {
        "紫色".to_string()
      } else if r > 120 && g < 60 && b > 100 {
        "深紫色".to_string()
      } else {
        "紫色系".to_string()
      }
    },
    // 青色系
    (r, g, b) if r < 100 && g > 120 && b > 120 => {
      if r < 50 && g > 180 && b > 180 {
        "青色".to_string()
      } else {
        "青色系".to_string()
      }
    },
    // 橙色系
    (r, g, b) if r > 150 && g > 80 && g < 150 && b < 100 => {
      "橙色系".to_string()
    },
    // 棕色系
    (r, g, b) if r > 80 && r < 160 && g > 50 && g < 120 && b > 20 && b < 80 => {
      "棕色系".to_string()
    },
    // 粉色系
    (r, g, b) if r > 180 && g > 120 && g < 180 && b > 120 && b < 180 => {
      "粉色系".to_string()
    },
    _ => "混合色".to_string()
  }
}

/// 基于图像特征的智能物体检测
fn detect_objects_from_features(
  width: u32, 
  height: u32, 
  aspect_ratio: f64, 
  colors: &[ColorInfo], 
  scene_type: &str
) -> Vec<DetectedObject> {
  let mut objects = Vec::new();
  
  // 基于宽高比推断可能的内容
  if aspect_ratio > 2.0 {
    objects.push(DetectedObject {
      name: "全景风景".to_string(),
      confidence: 0.85,
      bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 1.0 },
      category: "风景".to_string(),
    });
  } else if aspect_ratio > 1.5 {
    objects.push(DetectedObject {
      name: "横向场景".to_string(),
      confidence: 0.75,
      bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 1.0 },
      category: "场景".to_string(),
    });
  } else if aspect_ratio < 0.67 {
    objects.push(DetectedObject {
      name: "人像构图".to_string(),
      confidence: 0.80,
      bbox: BoundingBox { x: 0.3, y: 0.1, width: 0.4, height: 0.8 },
      category: "人像".to_string(),
    });
  } else if aspect_ratio > 0.9 && aspect_ratio < 1.1 {
    objects.push(DetectedObject {
      name: "方形构图".to_string(),
      confidence: 0.90,
      bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 1.0 },
      category: "构图".to_string(),
    });
  }
  
  // 基于颜色特征推断内容
  if let Some(dominant_color) = colors.first() {
    match dominant_color.rgb {
      // 绿色主导 - 自然环境
      (r, g, b) if g > r + 30 && g > b + 30 => {
        objects.push(DetectedObject {
          name: "植被环境".to_string(),
          confidence: 0.80,
          bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 0.7 },
          category: "自然".to_string(),
        });
        if g > 150 {
          objects.push(DetectedObject {
            name: "绿色植物".to_string(),
            confidence: 0.75,
            bbox: BoundingBox { x: 0.1, y: 0.1, width: 0.8, height: 0.6 },
            category: "植物".to_string(),
          });
        }
      },
      // 蓝色主导 - 天空或水
      (r, g, b) if b > r + 30 && b > g + 30 => {
        objects.push(DetectedObject {
          name: "蓝色背景".to_string(),
          confidence: 0.75,
          bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 0.5 },
          category: "背景".to_string(),
        });
        if b > 150 && r < 100 && g < 150 {
          objects.push(DetectedObject {
            name: "天空或水体".to_string(),
            confidence: 0.70,
            bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 0.6 },
            category: "自然元素".to_string(),
          });
        }
      },
      // 暖色调 - 可能是日落或人工照明
      (r, g, b) if r > g + 20 && r > b + 20 && r > 150 => {
        objects.push(DetectedObject {
          name: "暖光环境".to_string(),
          confidence: 0.65,
          bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 1.0 },
          category: "光照".to_string(),
        });
        if r > 200 && g > 100 && g < 180 && b < 100 {
          objects.push(DetectedObject {
            name: "日落色彩".to_string(),
            confidence: 0.70,
            bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 0.4 },
            category: "天空".to_string(),
          });
        }
      },
      _ => {}
    }
  }
  
  // 基于场景类型添加特定检测
  match scene_type {
    "风景" => {
      objects.push(DetectedObject {
        name: "风景画面".to_string(),
        confidence: 0.85,
        bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 1.0 },
        category: "场景类型".to_string(),
      });
    },
    "人像" => {
      objects.push(DetectedObject {
        name: "人像主体".to_string(),
        confidence: 0.75,
        bbox: BoundingBox { x: 0.25, y: 0.1, width: 0.5, height: 0.8 },
        category: "人物".to_string(),
      });
    },
    _ => {}
  }
  
  // 基于分辨率添加质量相关检测
  let total_pixels = width * height;
  if total_pixels > 8_000_000 {
    objects.push(DetectedObject {
      name: "高质量图像".to_string(),
      confidence: 0.95,
      bbox: BoundingBox { x: 0.0, y: 0.0, width: 1.0, height: 1.0 },
      category: "质量".to_string(),
    });
  }
  
  objects
}
