import { AIAnalysisResult, ImageAnalysisRequest, AIModelConfig, AnalysisProgress } from '@/type/ai'

export interface GGUFModelConfig extends Omit<AIModelConfig, 'labelsPath'> {
  modelPath: string
  contextSize: number
  threads: number
  gpuLayers: number
  useMlock: boolean
  useMMap: boolean
}

export class GGUFAnalysisService {
  private model: any = null
  private isInitialized = false
  private config: GGUFModelConfig

  constructor(config: Partial<GGUFModelConfig> = {}) {
    this.config = {
      modelPath: '/models/gguf/Qwen3-4B-Q4_K_M.gguf', // ä½¿ç”¨æ‚¨æœ¬åœ°çš„æ¨¡å‹
      threshold: 0.6,
      maxResults: 8,
      language: 'zh-CN',
      contextSize: 2048,
      threads: 4,
      gpuLayers: 0,
      useMlock: false,
      useMMap: true,
      ...config
    }
  }

  async initialize(): Promise<void> {
    if (this.isInitialized) return

    try {
      console.log('ğŸ”„ å¼€å§‹åˆå§‹åŒ– GGUF æ¨¡å‹...')
      console.log('ğŸ“ æ¨¡å‹è·¯å¾„:', this.config.modelPath)
      console.log('âš™ï¸ é…ç½®å‚æ•°:', this.config)

      // æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      try {
        const response = await fetch(this.config.modelPath, { method: 'HEAD' })
        if (!response.ok) {
          throw new Error(`æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: ${response.status}`)
        }
        console.log('âœ… æ¨¡å‹æ–‡ä»¶æ£€æŸ¥é€šè¿‡')
      } catch (fetchError) {
        console.warn('âš ï¸ æ¨¡å‹æ–‡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œç»§ç»­å°è¯•åŠ è½½:', fetchError)
      }

      // åŠ¨æ€å¯¼å…¥ llama-node åº“
      console.log('ğŸ“¦ æ­£åœ¨åŠ è½½ llama-node åº“...')
      const llamaModule = await import('@llama-node/llama-cpp')
      console.log('âœ… llama-node åº“åŠ è½½æˆåŠŸ')
      
      // åˆå§‹åŒ–æ¨¡å‹
      console.log('ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹å®ä¾‹...')
      this.model = new llamaModule.LLama()
      
      // åŠ è½½æ¨¡å‹
      console.log('ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹æ–‡ä»¶...')
      await this.model.load({
        modelPath: this.config.modelPath,
        contextSize: this.config.contextSize,
        threads: this.config.threads,
        gpuLayers: this.config.gpuLayers,
        useMlock: this.config.useMlock,
        useMMap: this.config.useMMap,
      })
      
      this.isInitialized = true
      console.log('ğŸ‰ GGUF æ¨¡å‹åŠ è½½æˆåŠŸ:', this.config.modelPath)
      console.log('ğŸ“Š æ¨¡å‹ä¿¡æ¯:', this.getModelInfo())
    } catch (error) {
      console.error('âŒ GGUF æ¨¡å‹åŠ è½½å¤±è´¥:', error)
      
      // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
      let errorMessage = 'GGUF æ¨¡å‹åˆå§‹åŒ–å¤±è´¥'
      if (error instanceof Error) {
        if (error.message.includes('æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨')) {
          errorMessage = 'GGUF æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„'
        } else if (error.message.includes('llama-node')) {
          errorMessage = 'llama-node åº“åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–å®‰è£…'
        } else if (error.message.includes('å†…å­˜')) {
          errorMessage = 'å†…å­˜ä¸è¶³ï¼Œæ— æ³•åŠ è½½æ¨¡å‹ï¼Œè¯·å…³é—­å…¶ä»–åº”ç”¨'
        } else {
          errorMessage = `GGUF æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: ${error.message}`
        }
      }
      
      throw new Error(errorMessage)
    }
  }

  async analyzeImage(request: ImageAnalysisRequest): Promise<AIAnalysisResult> {
    if (!this.isInitialized) {
      await this.initialize()
    }

    if (!this.model) {
      throw new Error('GGUF æ¨¡å‹æœªåŠ è½½')
    }

    const startTime = Date.now()

    try {
      // å°†å›¾ç‰‡è½¬æ¢ä¸º base64 æˆ–äºŒè¿›åˆ¶æ•°æ®
      const imageData = await this.preprocessImage(request.imageFile)
      
      // æ„å»ºæç¤ºè¯
      const prompt = this.buildPrompt(request.language || 'zh-CN')
      
      // ä½¿ç”¨ GGUF æ¨¡å‹è¿›è¡Œæ¨ç†
      const response = await this.model.complete({
        prompt: prompt + '\n' + imageData,
        maxTokens: 512,
        temperature: 0.7,
        topP: 0.9,
        stop: ['\n\n', 'ã€‚', '.', '!', '?']
      })

      // è§£ææ¨¡å‹è¾“å‡º
      const result = this.parseResponse(response.text, request.language || 'zh-CN')
      
      return {
        ...result,
        processingTime: Date.now() - startTime
      }
    } catch (error) {
      console.error('GGUF å›¾ç‰‡åˆ†æå¤±è´¥:', error)
      throw new Error('GGUF å›¾ç‰‡åˆ†æå¤±è´¥')
    }
  }

  private async preprocessImage(imageFile: File): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader()
      reader.onload = () => {
        try {
          // å°†å›¾ç‰‡è½¬æ¢ä¸º base64
          const base64 = reader.result as string
          
          // å¯¹äºGGUFæ¨¡å‹ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦è°ƒæ•´å›¾ç‰‡æ ¼å¼
          // ç§»é™¤ data:image/...;base64, å‰ç¼€ï¼Œåªä¿ç•™base64æ•°æ®
          const base64Data = base64.split(',')[1]
          
          console.log('ğŸ–¼ï¸ å›¾ç‰‡é¢„å¤„ç†å®Œæˆï¼Œå¤§å°:', base64Data.length, 'å­—ç¬¦')
          resolve(base64Data)
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
          reject(new Error('å›¾ç‰‡é¢„å¤„ç†å¤±è´¥: ' + errorMessage))
        }
      }
      reader.onerror = () => reject(new Error('å›¾ç‰‡è¯»å–å¤±è´¥'))
      reader.readAsDataURL(imageFile)
    })
  }

  private buildPrompt(language: string): string {
    if (language === 'zh-CN') {
      return `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆ†æAIåŠ©æ‰‹ã€‚è¯·ä»”ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œè¯†åˆ«å…¶ä¸­çš„ä¸»è¦ç‰©ä½“ã€åœºæ™¯ã€é¢œè‰²ã€é£æ ¼ç­‰ç‰¹å¾ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š

æ ‡ç­¾ï¼š[ç”¨é€—å·åˆ†éš”çš„å…³é”®è¯ï¼Œå¦‚ï¼šäººç‰©, é£æ™¯, å»ºç­‘, è‡ªç„¶, ç°ä»£]
æè¿°ï¼š[ç”¨2-3å¥è¯è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦å…ƒç´ ã€åœºæ™¯ã€æ°›å›´ç­‰]

è¦æ±‚ï¼š
1. æ ‡ç­¾è¦å‡†ç¡®ã€å…·ä½“ã€æœ‰æ„ä¹‰
2. æè¿°è¦è¯¦ç»†ã€ç”ŸåŠ¨ã€å‡†ç¡®
3. åˆ†æè¦å…¨é¢ï¼ŒåŒ…æ‹¬è§†è§‰å…ƒç´ å’Œæƒ…æ„Ÿæ°›å›´
4. ä½¿ç”¨ä¸­æ–‡è¾“å‡º

ç°åœ¨è¯·åˆ†æè¿™å¼ å›¾ç‰‡ï¼š`
    } else {
      return `You are a professional image analysis AI assistant. Please carefully analyze this image, identifying the main objects, scenes, colors, styles, and other features.

Please output the analysis results in the following format:

Tags: [comma-separated keywords, e.g., person, landscape, building, nature, modern]
Description: [describe the image content in 2-3 sentences, including main elements, scene, atmosphere, etc.]

Requirements:
1. Tags should be accurate, specific, and meaningful
2. Description should be detailed, vivid, and accurate
3. Analysis should be comprehensive, including visual elements and emotional atmosphere
4. Use English output

Now please analyze this image:`
    }
  }

  private parseResponse(response: string, language: string): Omit<AIAnalysisResult, 'processingTime'> {
    try {
      // è§£ææ¨¡å‹è¾“å‡º
      const lines = response.split('\n')
      let tags: string[] = []
      let description = ''

      for (const line of lines) {
        if (line.includes('æ ‡ç­¾:') || line.includes('Tags:')) {
          const tagMatch = line.match(/[ï¼š:]\s*(.+)/)
          if (tagMatch) {
            tags = tagMatch[1].split(',').map(tag => tag.trim()).filter(tag => tag)
          }
        } else if (line.includes('æè¿°:') || line.includes('Description:')) {
          const descMatch = line.match(/[ï¼š:]\s*(.+)/)
          if (descMatch) {
            description = descMatch[1].trim()
          }
        }
      }

      // å¦‚æœæ²¡æœ‰è§£æåˆ°ç»“æœï¼Œä½¿ç”¨é»˜è®¤å¤„ç†
      if (tags.length === 0 || !description) {
        return this.fallbackResponse(response, language)
      }

      // è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºæ ‡ç­¾æ•°é‡å’Œæè¿°é•¿åº¦ï¼‰
      const confidence = Math.min(0.9, 0.5 + (tags.length * 0.1) + (description.length * 0.01))

      return {
        tags,
        description,
        confidence
      }
    } catch (error) {
      console.warn('è§£æ GGUF å“åº”å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†:', error)
      return this.fallbackResponse(response, language)
    }
  }

  private fallbackResponse(response: string, language: string): Omit<AIAnalysisResult, 'processingTime'> {
    // æå–å…³é”®è¯ä½œä¸ºæ ‡ç­¾
    const words = response.split(/\s+/).filter(word => 
      word.length > 2 && /^[a-zA-Z\u4e00-\u9fa5]+$/.test(word)
    )
    
    const tags = words.slice(0, this.config.maxResults)
    const description = language === 'zh-CN' 
      ? 'AI åˆ†æå®Œæˆï¼Œå·²è¯†åˆ«ç›¸å…³æ ‡ç­¾'
      : 'AI analysis completed, tags identified'

    return {
      tags,
      description,
      confidence: 0.6
    }
  }

  async analyzeImageWithProgress(
    request: ImageAnalysisRequest,
    onProgress: (progress: AnalysisProgress) => void
  ): Promise<AIAnalysisResult> {
    try {
      onProgress({
        status: 'loading',
        progress: 0,
        message: 'æ­£åœ¨åŠ è½½ GGUF æ¨¡å‹...'
      })

      await this.initialize()

      onProgress({
        status: 'processing',
        progress: 50,
        message: 'æ­£åœ¨åˆ†æå›¾ç‰‡...'
      })

      const result = await this.analyzeImage(request)

      onProgress({
        status: 'completed',
        progress: 100,
        message: 'åˆ†æå®Œæˆ',
        result
      })

      return result
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'åˆ†æå¤±è´¥'
      
      onProgress({
        status: 'error',
        progress: 0,
        message: 'åˆ†æå¤±è´¥',
        error: errorMessage
      })

      throw error
    }
  }

  // è·å–æ¨¡å‹ä¿¡æ¯
  getModelInfo(): any {
    if (!this.model) return null
    
    return {
      modelPath: this.config.modelPath,
      contextSize: this.config.contextSize,
      threads: this.config.threads,
      gpuLayers: this.config.gpuLayers,
      isLoaded: this.isInitialized
    }
  }

  // æ¸…ç†èµ„æº
  dispose(): void {
    if (this.model) {
      try {
        this.model.dispose()
        this.model = null
      } catch (error) {
        console.warn('æ¸…ç† GGUF æ¨¡å‹èµ„æºå¤±è´¥:', error)
      }
    }
    this.isInitialized = false
  }
} 